"""å¯©è¨ˆåŸ·è¡Œå™¨æ¨¡çµ„ã€‚

æä¾›å¯©è¨ˆç³»çµ±çš„æ ¸å¿ƒåŸ·è¡Œé‚è¼¯ï¼Œå”èª¿ API å®¢æˆ¶ç«¯ã€åˆ†è©å™¨èˆ‡æª¢æ¸¬å™¨ã€‚
"""

from datetime import datetime
from pathlib import Path

from llm_testkit.audit.config import AuditConfig
from llm_testkit.audit.detectors import (
    ArithmeticJsonDetector,
    BaseDetector,
    DetectorResult,
    PerturbationDetector,
    StyleBiasDetector,
    TokenizerFingerprintDetector,
)
from llm_testkit.backend.openai_api import OpenAICompatibleAPI
from llm_testkit.core.tokenizer import Tokenizer
from llm_testkit.utils.io import write_json
from llm_testkit.utils.logging import setup_logger


class AuditRunner:
    """å¯©è¨ˆåŸ·è¡Œå™¨ã€‚

    å”èª¿æ‰€æœ‰å¯©è¨ˆçµ„ä»¶ï¼ŒåŸ·è¡Œæª¢æ¸¬å™¨ä¸¦ç”¢ç”Ÿå ±å‘Šã€‚

    Attributes:
        config: å¯©è¨ˆé…ç½®
        logger: æ—¥èªŒè¨˜éŒ„å™¨
        api: API å®¢æˆ¶ç«¯
        tokenizer: åˆ†è©å™¨
        detectors: æª¢æ¸¬å™¨è¨»å†Šè¡¨
    """

    def __init__(self, config: AuditConfig):
        """åˆå§‹åŒ–å¯©è¨ˆåŸ·è¡Œå™¨ã€‚

        Args:
            config: å¯©è¨ˆé…ç½®
        """
        self.config = config
        self.logger = setup_logger("audit", level="INFO")

        # åˆå§‹åŒ– API å®¢æˆ¶ç«¯ï¼ˆé‡ç”¨ç¾æœ‰é¡åˆ¥ï¼‰
        self.logger.info(f"åˆå§‹åŒ– API å®¢æˆ¶ç«¯: {config.endpoint.url}")
        self.api = OpenAICompatibleAPI(
            model_name=config.endpoint.model,
            base_url=config.endpoint.url,
            api_key=config.endpoint.api_key,
        )

        # åˆå§‹åŒ–åˆ†è©å™¨
        self.logger.info(f"åˆå§‹åŒ–åˆ†è©å™¨: {config.tokenizer.model_name_or_path}")
        self.tokenizer = Tokenizer(model_name_or_path=config.tokenizer.model_name_or_path)

        # è¨»å†Šæª¢æ¸¬å™¨
        self.detectors: dict[str, BaseDetector] = {
            "tokenizer_fingerprint": TokenizerFingerprintDetector(),
            "perturbation": PerturbationDetector(),
            "arithmetic_json": ArithmeticJsonDetector(),
            "style_bias": StyleBiasDetector(),
        }

        self.logger.info(f"å·²è¨»å†Š {len(self.detectors)} å€‹æª¢æ¸¬å™¨")

    async def run_suite(self, suite_name: str) -> list[DetectorResult]:
        """åŸ·è¡Œæ¸¬è©¦å¥—ä»¶ã€‚

        ä¾åºåŸ·è¡Œå¥—ä»¶ä¸­çš„æ‰€æœ‰æª¢æ¸¬å™¨ï¼Œå–®ä¸€æª¢æ¸¬å™¨å¤±æ•—ä¸å½±éŸ¿å…¶ä»–æª¢æ¸¬å™¨ã€‚

        Args:
            suite_name: å¥—ä»¶åç¨±ï¼ˆå¦‚ "quick"ï¼‰

        Returns:
            æª¢æ¸¬çµæœåˆ—è¡¨

        Raises:
            ValueError: å¥—ä»¶åç¨±ä¸å­˜åœ¨
        """
        if suite_name not in self.config.suites:
            available = ", ".join(self.config.suites.keys())
            raise ValueError(f"æ¸¬è©¦å¥—ä»¶ '{suite_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å¥—ä»¶: {available}")

        detector_names = self.config.suites[suite_name]
        results = []

        print(f"\n{'=' * 70}")
        print(f"é–‹å§‹åŸ·è¡Œæ¸¬è©¦å¥—ä»¶: {suite_name}")
        print(f"åŒ…å« {len(detector_names)} å€‹æª¢æ¸¬å™¨")
        print(f"{'=' * 70}\n")

        for idx, name in enumerate(detector_names, 1):
            detector = self.detectors.get(name)

            if not detector:
                print(f"[{idx}/{len(detector_names)}] âš ï¸  æª¢æ¸¬å™¨ '{name}' ä¸å­˜åœ¨ï¼Œè·³é")
                results.append(
                    DetectorResult(
                        name=name, passed=False, metrics={}, notes=f"æª¢æ¸¬å™¨ '{name}' æœªè¨»å†Š"
                    )
                )
                continue

            print(f"[{idx}/{len(detector_names)}] ğŸ”„ åŸ·è¡Œæª¢æ¸¬å™¨: {name}")

            try:
                result = await detector.run(
                    api=self.api,
                    tokenizer=self.tokenizer,
                    decoding=self.config.decoding,
                    thresholds=self.config.thresholds,
                )
                results.append(result)

                # é¡¯ç¤ºçµæœ
                status_icon = "âœ…" if result.passed else "âŒ"
                status_text = "é€šé" if result.passed else "å¤±æ•—"
                print(f"[{idx}/{len(detector_names)}] {status_icon} {name}: {status_text}")

                # é¡¯ç¤ºé—œéµæŒ‡æ¨™
                self._print_metrics_summary(result)

                if result.notes:
                    print(f"     âš ï¸  {result.notes}")

                print()  # ç©ºè¡Œåˆ†éš”

            except Exception as e:
                print(f"[{idx}/{len(detector_names)}] âŒ {name}: åŸ·è¡ŒéŒ¯èª¤")
                print(f"     éŒ¯èª¤: {str(e)}")
                print()
                self.logger.error(f"æª¢æ¸¬å™¨ '{name}' åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
                results.append(
                    DetectorResult(name=name, passed=False, metrics={}, notes=f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
                )

        # çµ±è¨ˆçµæœ
        passed_count = sum(1 for r in results if r.passed)
        total_count = len(results)

        print(f"{'=' * 70}")
        print(f"æ¸¬è©¦å¥—ä»¶å®Œæˆ: {passed_count}/{total_count} é€šé")
        print(f"{'=' * 70}\n")

        return results

    def _print_metrics_summary(self, result: DetectorResult) -> None:
        """é¡¯ç¤ºæª¢æ¸¬å™¨æŒ‡æ¨™æ‘˜è¦ã€‚

        Args:
            result: æª¢æ¸¬çµæœ
        """
        # æ ¹æ“šæª¢æ¸¬å™¨é¡å‹é¡¯ç¤ºé—œéµæŒ‡æ¨™
        if result.name == "tokenizer_fingerprint":
            avg_diff = result.metrics.get("avg_token_diff_pct")
            threshold = result.metrics.get("threshold")
            samples = result.metrics.get("samples", 0)
            if avg_diff is not None:
                print(f"     å¹³å‡åå·®: {avg_diff}% (é–¾å€¼: â‰¤{threshold}%) | æ¨£æœ¬æ•¸: {samples}")

        elif result.name == "perturbation":
            top1_pct = result.metrics.get("top1_change_pct")
            threshold = result.metrics.get("threshold")
            pairs = result.metrics.get("pairs", 0)
            if top1_pct is not None:
                print(f"     Top-1 è®Šæ›´ç‡: {top1_pct}% (é–¾å€¼: â‰¤{threshold}%) | æ¸¬è©¦å°æ•¸: {pairs}")

        elif result.name == "arithmetic_json":
            arith_acc = result.metrics.get("arithmetic_acc")
            json_valid = result.metrics.get("json_valid_sample")
            threshold = result.metrics.get("threshold_arithmetic")
            if arith_acc is not None:
                print(
                    f"     ç®—è¡“æ­£ç¢ºç‡: {arith_acc} (é–¾å€¼: â‰¥{threshold}) | JSON åˆæ³•: {json_valid}"
                )

        elif result.name == "style_bias":
            prefix_rate = result.metrics.get("fixed_prefix_rate")
            violation_rate = result.metrics.get("format_violation_rate")
            threshold_prefix = result.metrics.get("threshold_prefix")
            threshold_violation = result.metrics.get("threshold_violation")
            if prefix_rate is not None:
                print(
                    f"     å›ºå®šå‰ç¶´ç‡: {prefix_rate} (é–¾å€¼: â‰¤{threshold_prefix}) | æ ¼å¼é•è¦ç‡: {violation_rate} (é–¾å€¼: â‰¤{threshold_violation})"
                )

    def generate_report(self, results: list[DetectorResult], output_dir: str | Path) -> None:
        """ç”¢ç”Ÿå ±å‘Šã€‚

        ç”¢ç”Ÿ JSON èˆ‡ Markdown å…©ç¨®æ ¼å¼çš„å ±å‘Šã€‚

        Args:
            results: æª¢æ¸¬çµæœåˆ—è¡¨
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().isoformat()

        # JSON å ±å‘Šï¼ˆé‡ç”¨ç¾æœ‰ IO å·¥å…·ï¼‰
        report_data = {
            "timestamp": timestamp,
            "endpoint": {"url": self.config.endpoint.url, "model": self.config.endpoint.model},
            "results": [r.to_dict() for r in results],
        }

        json_path = output_dir / "report.json"
        write_json(report_data, json_path)
        self.logger.info(f"JSON å ±å‘Šå·²ç”¢ç”Ÿ: {json_path}")

        # Markdown å ±å‘Š
        md_lines = [
            "# LLM API å¯©è¨ˆå ±å‘Š",
            "",
            "## åŸºæœ¬è³‡è¨Š",
            "",
            f"- **æ™‚é–“æˆ³è¨˜:** {timestamp}",
            f"- **API ç«¯é»:** {self.config.endpoint.url}",
            f"- **æ¨¡å‹åç¨±:** {self.config.endpoint.model}",
            f"- **åˆ†è©å™¨:** {self.config.tokenizer.model_name_or_path}",
            "",
            "## æ¸¬è©¦æ‘˜è¦",
            "",
        ]

        # çµ±è¨ˆæ‘˜è¦
        passed_count = sum(1 for r in results if r.passed)
        total_count = len(results)
        pass_rate = (passed_count / total_count * 100) if total_count > 0 else 0

        # æ•´é«”åˆ¤å®š
        overall_status = "âœ… é€šé" if passed_count == total_count else "âŒ å¤±æ•—"

        md_lines.extend(
            [
                "| é …ç›® | æ•¸å€¼ |",
                "|------|------|",
                f"| **æ•´é«”ç‹€æ…‹** | {overall_status} |",
                f"| **ç¸½æ¸¬è©¦æ•¸** | {total_count} |",
                f"| **é€šéæ•¸** | {passed_count} |",
                f"| **å¤±æ•—æ•¸** | {total_count - passed_count} |",
                f"| **é€šéç‡** | {pass_rate:.1f}% |",
                "",
                "## è©³ç´°çµæœ",
                "",
            ]
        )

        # è©³ç´°çµæœ
        for result in results:
            status_icon = "âœ…" if result.passed else "âŒ"
            status_text = "é€šé" if result.passed else "å¤±æ•—"

            # æª¢æ¸¬å™¨æ¨™é¡Œ
            detector_title = self._get_detector_title(result.name)
            md_lines.append(f"### {status_icon} {detector_title}")
            md_lines.append("")
            md_lines.append(f"**ç‹€æ…‹:** {status_text}")
            md_lines.append("")

            # æŒ‡æ¨™è¡¨æ ¼
            if result.metrics:
                md_lines.append("**æŒ‡æ¨™:**")
                md_lines.append("")

                # æ ¹æ“šæª¢æ¸¬å™¨é¡å‹ç”¢ç”Ÿä¸åŒçš„è¡¨æ ¼
                if result.name == "tokenizer_fingerprint":
                    md_lines.extend(self._format_fingerprint_metrics(result))
                elif result.name == "perturbation":
                    md_lines.extend(self._format_perturbation_metrics(result))
                elif result.name == "arithmetic_json":
                    md_lines.extend(self._format_arithmetic_metrics(result))
                elif result.name == "style_bias":
                    md_lines.extend(self._format_style_metrics(result))
                else:
                    # é è¨­æ ¼å¼
                    md_lines.append("| æŒ‡æ¨™ | æ•¸å€¼ |")
                    md_lines.append("|------|------|")
                    for key, value in result.metrics.items():
                        md_lines.append(f"| {key} | {value} |")

                md_lines.append("")

            # è§£è®€èªªæ˜
            interpretation = self._get_interpretation(result)
            if interpretation:
                md_lines.append("**è§£è®€:**")
                md_lines.append("")
                md_lines.append(interpretation)
                md_lines.append("")

            # å‚™è¨»
            if result.notes:
                md_lines.append(f"**å‚™è¨»:** {result.notes}")
                md_lines.append("")

            md_lines.append("---")
            md_lines.append("")

        md_path = output_dir / "report.md"
        md_path.write_text("\n".join(md_lines), encoding="utf-8")
        self.logger.info(f"Markdown å ±å‘Šå·²ç”¢ç”Ÿ: {md_path}")

        self.logger.info(f"å ±å‘Šå·²ç”¢ç”Ÿè‡³ç›®éŒ„: {output_dir}")

    def _get_detector_title(self, name: str) -> str:
        """å–å¾—æª¢æ¸¬å™¨çš„ä¸­æ–‡æ¨™é¡Œã€‚

        Args:
            name: æª¢æ¸¬å™¨åç¨±

        Returns:
            ä¸­æ–‡æ¨™é¡Œ
        """
        titles = {
            "tokenizer_fingerprint": "åˆ†è©å™¨æŒ‡ç´‹æª¢æ¸¬",
            "perturbation": "å¾®æ“¾ç©©å®šæ€§æª¢æ¸¬",
            "arithmetic_json": "ç®—è¡“èˆ‡ JSON çµæ§‹å®Œæ•´æ€§æª¢æ¸¬",
            "style_bias": "é¢¨æ ¼åç§»æª¢æ¸¬",
        }
        return titles.get(name, name)

    def _format_fingerprint_metrics(self, result: DetectorResult) -> list[str]:
        """æ ¼å¼åŒ–åˆ†è©å™¨æŒ‡ç´‹æª¢æ¸¬çš„æŒ‡æ¨™ã€‚"""
        lines = ["| æŒ‡æ¨™ | æ•¸å€¼ | é–¾å€¼ | ç‹€æ…‹ |", "|------|------|------|------|"]

        avg_diff = result.metrics.get("avg_token_diff_pct")
        threshold = result.metrics.get("threshold")
        samples = result.metrics.get("samples", 0)
        success_rate = result.metrics.get("success_rate", 0)

        if avg_diff is not None:
            status = "âœ…" if avg_diff <= threshold else "âŒ"
            lines.append(f"| å¹³å‡ token åå·® | {avg_diff}% | â‰¤ {threshold}% | {status} |")

        max_diff = result.metrics.get("max_token_diff_pct")
        if max_diff is not None:
            lines.append(f"| æœ€å¤§ token åå·® | {max_diff}% | - | - |")

        lines.append(f"| æ¸¬è©¦æ¨£æœ¬æ•¸ | {samples} | - | - |")
        lines.append(f"| æˆåŠŸç‡ | {success_rate * 100:.0f}% | - | - |")

        return lines

    def _format_perturbation_metrics(self, result: DetectorResult) -> list[str]:
        """æ ¼å¼åŒ–å¾®æ“¾ç©©å®šæ€§æª¢æ¸¬çš„æŒ‡æ¨™ã€‚"""
        lines = ["| æŒ‡æ¨™ | æ•¸å€¼ | é–¾å€¼ | ç‹€æ…‹ |", "|------|------|------|------|"]

        top1_pct = result.metrics.get("top1_change_pct")
        threshold = result.metrics.get("threshold")
        pairs = result.metrics.get("pairs", 0)
        success_rate = result.metrics.get("success_rate", 0)

        if top1_pct is not None:
            status = "âœ…" if top1_pct <= threshold else "âŒ"
            lines.append(f"| Top-1 è®Šæ›´ç‡ | {top1_pct}% | â‰¤ {threshold}% | {status} |")

        hamming = result.metrics.get("avg_hamming@10")
        if hamming is not None:
            lines.append(f"| å¹³å‡ Hamming è·é›¢ (å‰10 token) | {hamming} | - | - |")

        lines.append(f"| æ¸¬è©¦å°æ•¸ | {pairs} | - | - |")
        lines.append(f"| æˆåŠŸç‡ | {success_rate * 100:.0f}% | - | - |")

        return lines

    def _format_arithmetic_metrics(self, result: DetectorResult) -> list[str]:
        """æ ¼å¼åŒ–ç®—è¡“èˆ‡ JSON æª¢æ¸¬çš„æŒ‡æ¨™ã€‚"""
        lines = ["| æŒ‡æ¨™ | æ•¸å€¼ | é–¾å€¼ | ç‹€æ…‹ |", "|------|------|------|------|"]

        arith_acc = result.metrics.get("arithmetic_acc")
        threshold_arith = result.metrics.get("threshold_arithmetic")

        if arith_acc is not None:
            status = "âœ…" if arith_acc >= threshold_arith else "âŒ"
            lines.append(f"| ç®—è¡“æ­£ç¢ºç‡ | {arith_acc} | â‰¥ {threshold_arith} | {status} |")

        correct = result.metrics.get("arithmetic_correct", 0)
        total = result.metrics.get("arithmetic_total", 0)
        lines.append(f"| ç®—è¡“æ¸¬è©¦ (æ­£ç¢º/ç¸½æ•¸) | {correct}/{total} | - | - |")

        json_valid = result.metrics.get("json_valid_sample")
        if json_valid is not None:
            status = "âœ…" if json_valid else "âŒ"
            lines.append(f"| JSON åˆæ³•æ€§ | {json_valid} | True | {status} |")

        success_rate = result.metrics.get("arithmetic_success_rate", 0)
        lines.append(f"| æˆåŠŸç‡ | {success_rate * 100:.0f}% | - | - |")

        return lines

    def _format_style_metrics(self, result: DetectorResult) -> list[str]:
        """æ ¼å¼åŒ–é¢¨æ ¼åç§»æª¢æ¸¬çš„æŒ‡æ¨™ã€‚"""
        lines = ["| æŒ‡æ¨™ | æ•¸å€¼ | é–¾å€¼ | ç‹€æ…‹ |", "|------|------|------|------|"]

        prefix_rate = result.metrics.get("fixed_prefix_rate")
        threshold_prefix = result.metrics.get("threshold_prefix")

        if prefix_rate is not None:
            status = "âœ…" if prefix_rate <= threshold_prefix else "âŒ"
            lines.append(f"| å›ºå®šå‰ç¶´å‡ºç¾ç‡ | {prefix_rate} | â‰¤ {threshold_prefix} | {status} |")

        violation_rate = result.metrics.get("format_violation_rate")
        threshold_violation = result.metrics.get("threshold_violation")

        if violation_rate is not None:
            status = "âœ…" if violation_rate <= threshold_violation else "âŒ"
            lines.append(f"| æ ¼å¼é•è¦ç‡ | {violation_rate} | â‰¤ {threshold_violation} | {status} |")

        success_rate = result.metrics.get("success_rate", 0)
        lines.append(f"| æˆåŠŸç‡ | {success_rate * 100:.0f}% | - | - |")

        return lines

    def _get_interpretation(self, result: DetectorResult) -> str:
        """å–å¾—æª¢æ¸¬çµæœçš„è§£è®€èªªæ˜ã€‚

        Args:
            result: æª¢æ¸¬çµæœ

        Returns:
            è§£è®€èªªæ˜æ–‡å­—
        """
        if result.name == "tokenizer_fingerprint":
            avg_diff = result.metrics.get("avg_token_diff_pct")
            if avg_diff is None:
                return "ç„¡æ³•å–å¾— token æ•¸é‡è³‡è¨Šï¼Œå¯èƒ½æ˜¯ API ä¸æ”¯æ´æˆ–ç¶²è·¯å•é¡Œã€‚"
            elif result.passed:
                return f"å¹³å‡ token æ•¸åå·®ç‚º {avg_diff}%ï¼Œåœ¨å¯æ¥å—ç¯„åœå…§ï¼Œè¡¨ç¤º API ä½¿ç”¨çš„åˆ†è©å™¨èˆ‡å®£ç¨±çš„æ¨¡å‹å®¶æ—ä¸€è‡´ã€‚"
            else:
                return f"å¹³å‡ token æ•¸åå·®ç‚º {avg_diff}%ï¼Œè¶…éé–¾å€¼ï¼Œå¯èƒ½è¡¨ç¤º API ä½¿ç”¨äº†ä¸åŒçš„åˆ†è©å™¨æˆ–æ¨¡å‹å®¶æ—ã€‚"

        elif result.name == "perturbation":
            top1_pct = result.metrics.get("top1_change_pct")
            if top1_pct is None:
                return "ç„¡æ³•å®Œæˆå¾®æ“¾æ¸¬è©¦ï¼Œå¯èƒ½æ˜¯ API è«‹æ±‚å¤±æ•—ã€‚"
            elif result.passed:
                return f"Top-1 token è®Šæ›´ç‡ç‚º {top1_pct}%ï¼Œåœ¨å¯æ¥å—ç¯„åœå…§ï¼Œè¡¨ç¤ºæ¨¡å‹åœ¨å¾®å°è¼¸å…¥æ“¾å‹•ä¸‹ä¿æŒç©©å®šï¼Œæœªæª¢æ¸¬åˆ°æ˜é¡¯çš„é‡åŒ–å½±éŸ¿ã€‚"
            else:
                return f"Top-1 token è®Šæ›´ç‡ç‚º {top1_pct}%ï¼Œè¶…éé–¾å€¼ï¼Œå¯èƒ½è¡¨ç¤ºæ¨¡å‹ä½¿ç”¨äº†ä½æ¯”ç‰¹é‡åŒ–æˆ–è§£ç¢¼æ ¸ä¸ç©©å®šã€‚"

        elif result.name == "arithmetic_json":
            arith_acc = result.metrics.get("arithmetic_acc")
            json_valid = result.metrics.get("json_valid_sample")
            if arith_acc is None:
                return "ç„¡æ³•å®Œæˆç®—è¡“æ¸¬è©¦ï¼Œå¯èƒ½æ˜¯ API è«‹æ±‚å¤±æ•—ã€‚"
            elif result.passed:
                return f"ç®—è¡“æ­£ç¢ºç‡ç‚º {arith_acc}ï¼ŒJSON è¼¸å‡ºåˆæ³•ï¼Œè¡¨ç¤ºæ¨¡å‹åœ¨ç²¾ç¢ºä»»å‹™ä¸Šè¡¨ç¾è‰¯å¥½ï¼Œæœªæª¢æ¸¬åˆ°æ˜é¡¯çš„é‡åŒ–å½±éŸ¿ã€‚"
            else:
                issues = []
                threshold = result.metrics.get("threshold_arithmetic", 0.9)
                if arith_acc < threshold:
                    issues.append(f"ç®—è¡“æ­£ç¢ºç‡ ({arith_acc}) ä½æ–¼é–¾å€¼ ({threshold})")
                if not json_valid:
                    issues.append("JSON è¼¸å‡ºä¸åˆæ³•")
                return f"æª¢æ¸¬åˆ°å•é¡Œï¼š{', '.join(issues)}ã€‚å¯èƒ½è¡¨ç¤ºæ¨¡å‹ä½¿ç”¨äº†é‡åŒ–æˆ–å­˜åœ¨å¼·åˆ¶å¾Œè™•ç†ã€‚"

        elif result.name == "style_bias":
            prefix_rate = result.metrics.get("fixed_prefix_rate")
            violation_rate = result.metrics.get("format_violation_rate")
            if prefix_rate is None:
                return "ç„¡æ³•å®Œæˆé¢¨æ ¼æ¸¬è©¦ï¼Œå¯èƒ½æ˜¯ API è«‹æ±‚å¤±æ•—ã€‚"
            elif result.passed:
                return f"å›ºå®šå‰ç¶´å‡ºç¾ç‡ç‚º {prefix_rate}ï¼Œæ ¼å¼é•è¦ç‡ç‚º {violation_rate}ï¼Œå‡åœ¨å¯æ¥å—ç¯„åœå…§ï¼Œæœªæª¢æ¸¬åˆ°æ˜é¡¯çš„å¾®èª¿å½±éŸ¿ã€‚"
            else:
                issues = []
                threshold_prefix = result.metrics.get("threshold_prefix", 0.2)
                threshold_violation = result.metrics.get("threshold_violation", 0.1)
                if prefix_rate > threshold_prefix:
                    issues.append(f"å›ºå®šå‰ç¶´å‡ºç¾ç‡ ({prefix_rate}) è¶…éé–¾å€¼ ({threshold_prefix})")
                if violation_rate > threshold_violation:
                    issues.append(f"æ ¼å¼é•è¦ç‡ ({violation_rate}) è¶…éé–¾å€¼ ({threshold_violation})")
                return f"æª¢æ¸¬åˆ°å•é¡Œï¼š{', '.join(issues)}ã€‚å¯èƒ½è¡¨ç¤ºæ¨¡å‹ç¶“éå¾®èª¿ï¼Œå°è‡´è¡Œç‚ºåç§»ã€‚"

        return ""

    async def close(self) -> None:
        """é—œé–‰è³‡æºã€‚

        é—œé–‰ API å®¢æˆ¶ç«¯é€£ç·šã€‚
        """
        self.logger.info("é—œé–‰ API å®¢æˆ¶ç«¯")
        await self.api.close()

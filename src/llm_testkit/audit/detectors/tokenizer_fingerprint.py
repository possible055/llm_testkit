"""åˆ†è©žå™¨æŒ‡ç´‹æª¢æ¸¬å™¨ã€‚

é€éŽç‰¹è£½å­—ä¸²æ¸¬è©¦ API å›žå‚³çš„ token æ•¸é‡æ˜¯å¦èˆ‡æœ¬åœ°åˆ†è©žå™¨ä¸€è‡´ï¼Œ
ç”¨æ–¼åˆ¤æ–· API æœå‹™å•†æ˜¯å¦ä½¿ç”¨äº†å®£ç¨±çš„åˆ†è©žå™¨/æ¨¡åž‹å®¶æ—ã€‚
"""

import asyncio

from llm_testkit.audit.config import DecodingConfig, ThresholdsConfig
from llm_testkit.audit.detectors.base import BaseDetector, DetectorResult
from llm_testkit.backend.openai_api import OpenAICompatibleAPI
from llm_testkit.core.tokenizer import Tokenizer


class TokenizerFingerprintDetector(BaseDetector):
    """åˆ†è©žå™¨æŒ‡ç´‹æª¢æ¸¬å™¨ã€‚

    ä½¿ç”¨åŒ…å«ç©ºç™½ã€Unicodeã€Emojiã€URLã€CJK æ··æŽ’çš„ç‰¹è£½å­—ä¸²æ¸¬è©¦
    API å›žå‚³çš„ prompt_tokens æ˜¯å¦èˆ‡æœ¬åœ°åˆ†è©žå™¨è¨ˆç®—çµæžœä¸€è‡´ã€‚

    æª¢æ¸¬é‚è¼¯ï¼š
    1. ä½¿ç”¨æœ¬åœ°åˆ†è©žå™¨è¨ˆç®—æ¸¬è©¦å­—ä¸²çš„ token æ•¸
    2. å‘¼å« API ä¸¦å¾ž usage.prompt_tokens å–å¾—é ç«¯è¨ˆç®—çš„ token æ•¸
    3. è¨ˆç®—åå·®ç™¾åˆ†æ¯”
    4. è‹¥å¹³å‡åå·®è¶…éŽé–¾å€¼ï¼Œæ¨™è¨˜ç‚ºã€Œé«˜åº¦æ‡·ç–‘éžè©²å®¶æ—ã€
    """

    # æ¸¬è©¦å­—ä¸²é›†ï¼šæ¶µè“‹ç©ºç™½ã€ZWJã€Emojiã€URLã€CJK æ··æŽ’ç­‰é‚Šç•Œæƒ…æ³
    FINGERPRINT_STRINGS = [
        "a a  a\n\nðŸ™‚http://ä¾‹.com/è·¯å¾„?x=1#é”š",
        "A" + (" " * 64) + "ðŸ‘¨â€ðŸ‘©â€ðŸ‘¦â€ðŸ‘¦",
        "é›¶å¯¬é€£å­—å…ƒï¼ša\u200db",
        "Emoji ZWJ: ðŸ‘©\u200dðŸ’»ðŸ‘¨\u200dðŸ‘©\u200dðŸ‘§\u200dðŸ‘¦",
    ]

    @property
    def name(self) -> str:
        """å›žå‚³æª¢æ¸¬å™¨åç¨±ã€‚"""
        return "tokenizer_fingerprint"

    async def run(
        self,
        api: OpenAICompatibleAPI,
        tokenizer: Tokenizer,
        decoding: DecodingConfig,
        thresholds: ThresholdsConfig,
    ) -> DetectorResult:
        """åŸ·è¡Œåˆ†è©žå™¨æŒ‡ç´‹æª¢æ¸¬ã€‚

        Args:
            api: API å®¢æˆ¶ç«¯
            tokenizer: æœ¬åœ°åˆ†è©žå™¨
            decoding: è§£ç¢¼åƒæ•¸
            thresholds: é–¾å€¼é…ç½®

        Returns:
            æª¢æ¸¬çµæžœï¼ŒåŒ…å«å¹³å‡åå·®ç™¾åˆ†æ¯”èˆ‡æ¨£æœ¬æ•¸
        """
        # æœ¬åœ°è¨ˆç®—æ‰€æœ‰ token æ•¸
        prompts = [f"è«‹åŽŸæ¨£å›žå‚³ä»¥ä¸‹æ–‡å­—ï¼š\n{test_str}" for test_str in self.FINGERPRINT_STRINGS]
        local_counts = [tokenizer.count(prompt) for prompt in prompts]

        # ä½µç™¼åŸ·è¡Œæ‰€æœ‰ API å‘¼å«
        tasks = []
        for prompt in prompts:
            messages = [{"role": "user", "content": prompt}]
            task = api.generate(
                messages=messages, temperature=decoding.temperature, max_tokens=decoding.max_tokens
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        diffs = []
        max_diff = 0.0
        failed_samples = 0
        no_usage_count = 0

        for local_count, result in zip(local_counts, results, strict=False):
            if isinstance(result, Exception):
                failed_samples += 1
                continue

            # æå– usage.prompt_tokens
            try:
                remote_count = result.usage.prompt_tokens if result.usage else None  # type: ignore
            except AttributeError:
                remote_count = None

            if remote_count is None:
                no_usage_count += 1
                continue

            # è¨ˆç®—åå·®ç™¾åˆ†æ¯”
            diff_pct = abs(local_count - remote_count) / max(1, local_count) * 100
            diffs.append(diff_pct)
            max_diff = max(max_diff, diff_pct)

        # è¨ˆç®—å¹³å‡åå·®
        avg_diff = sum(diffs) / len(diffs) if diffs else None
        success_rate = len(diffs) / len(prompts) if prompts else 0.0

        # åˆ¤å®šé€šéŽæ¢ä»¶ï¼šæœ‰ usage è³‡è¨Šä¸”å¹³å‡åå·®åœ¨é–¾å€¼å…§
        if avg_diff is None:
            passed = False
            if no_usage_count > 0:
                notes = f"API æœªå›žå‚³ usage è³‡è¨Šï¼ˆ{no_usage_count} å€‹æ¨£æœ¬ï¼‰ï¼Œç„¡æ³•é©—è­‰åˆ†è©žå™¨"
            else:
                notes = f"æ‰€æœ‰è«‹æ±‚å¤±æ•—ï¼ˆ{failed_samples} å€‹æ¨£æœ¬ï¼‰"
        else:
            passed = avg_diff <= thresholds.fingerprint_avg_diff_pct
            notes = ""
            if failed_samples > 0:
                notes = f"è­¦å‘Šï¼š{failed_samples} å€‹æ¨£æœ¬è«‹æ±‚å¤±æ•—"

        return DetectorResult(
            name=self.name,
            passed=passed,
            metrics={
                "avg_token_diff_pct": round(avg_diff, 2) if avg_diff is not None else None,
                "max_token_diff_pct": round(max_diff, 2) if diffs else None,
                "samples": len(diffs),
                "failed_samples": failed_samples,
                "success_rate": round(success_rate, 2),
                "threshold": thresholds.fingerprint_avg_diff_pct,
            },
            notes=notes,
        )

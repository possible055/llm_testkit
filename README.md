# LLM TestKit

LLM TestKit æ˜¯ä¸€å€‹ Python å·¥å…·åŒ…ï¼Œå°ˆç‚ºæ¸¬è©¦èˆ‡è©•ä¼° LLMï¼ˆå¤§å‹èªè¨€æ¨¡å‹ï¼‰æ‡‰ç”¨è€Œè¨­è¨ˆã€‚ç›®å‰æä¾› LLM API é»‘ç›’å¯©è¨ˆåŠŸèƒ½ï¼Œç”¨æ–¼é©—è­‰ç¬¬ä¸‰æ–¹ API æœå‹™å•†æä¾›çš„æ¨¡å‹æ˜¯å¦èˆ‡å…¶å®£ç¨±çš„æ¨¡å‹ä¸€è‡´ã€‚

## åŠŸèƒ½ç‰¹æ€§

### LLM API é»‘ç›’å¯©è¨ˆ (`audit`)

é€éã€Œåˆ†è©å™¨æŒ‡ç´‹ + å£“åŠ›æ¸¬è©¦ + åˆ†ä½ˆæª¢æŸ¥ã€ä¸‰å±¤äº¤å‰é©—è­‰ï¼Œæª¢æ¸¬æ¨¡å‹æ˜¯å¦è¢«å¾®èª¿ã€é‡åŒ–æˆ–æ›¿æ›ã€‚

**æ ¸å¿ƒæª¢æ¸¬å™¨ï¼š**

1. **åˆ†è©å™¨æŒ‡ç´‹æª¢æ¸¬** (`tokenizer_fingerprint`)
   - ä½¿ç”¨ç‰¹è£½å­—ä¸²æ¸¬è©¦é›†ï¼ˆç©ºç™½ã€Unicodeã€Emojiã€URLã€CJK æ··æ’ï¼‰
   - æ¯”å° API å›å‚³çš„ token æ•¸èˆ‡æœ¬åœ°åˆ†è©å™¨è¨ˆç®—çµæœ
   - æª¢æ¸¬æ¨¡å‹å®¶æ—æ˜¯å¦æ­£ç¢º

2. **å¾®æ“¾ç©©å®šæ€§æª¢æ¸¬** (`perturbation`)
   - å°æç¤ºé€²è¡Œå¾®å°æ“¾å‹•ï¼ˆæœ«å°¾ç©ºç™½ã€æ›è¡Œã€åŒç¾©æ›¿æ›ï¼‰
   - åœ¨ temperature=0 ä¸‹æ¯”è¼ƒè¼¸å‡ºå·®ç•°
   - æª¢æ¸¬ä½æ¯”ç‰¹é‡åŒ–æˆ–ç²—ç³™è§£ç¢¼æ ¸è·¡è±¡

3. **ç®—è¡“èˆ‡ JSON çµæ§‹å®Œæ•´æ€§æª¢æ¸¬** (`arithmetic_json`)
   - æ¸¬è©¦ 2-4 ä½æ•¸ä¹˜æ³•é‹ç®—èƒ½åŠ›
   - é©—è­‰ JSON çµæ§‹åŒ–è¼¸å‡ºèƒ½åŠ›
   - æª¢æ¸¬é‡åŒ–å°ç²¾ç¢ºä»»å‹™çš„å½±éŸ¿

4. **é¢¨æ ¼åç§»æª¢æ¸¬** (`style_bias`)
   - ä½¿ç”¨å¼·æ ¼å¼è¦æ±‚çš„æç¤º
   - æª¢æ¸¬å›ºå®šå‰è¨€ï¼ˆå¦‚ã€ŒSureã€ã€ŒæŠ±æ­‰ã€ï¼‰èˆ‡æ ¼å¼é•è¦
   - è­˜åˆ¥å¾®èª¿å°è‡´çš„è¡Œç‚ºè®ŠåŒ–

## ç³»çµ±éœ€æ±‚

- Python 3.12+
- pipï¼ˆPython å¥—ä»¶ç®¡ç†å™¨ï¼‰

## å®‰è£

### åŸºæœ¬å®‰è£

```bash
# å¾å°ˆæ¡ˆæ ¹ç›®éŒ„å®‰è£
pip install -e .
```

### ä¾è³´èªªæ˜

æ ¸å¿ƒä¾è³´æœƒè‡ªå‹•å®‰è£ï¼š

- `openai>=2.6.0` - OpenAI API å®¢æˆ¶ç«¯ï¼ˆæ”¯æ´ç›¸å®¹ APIï¼‰
- `anthropic>=0.40.0` - Anthropic API å®¢æˆ¶ç«¯ï¼ˆæ”¯æ´ Claude æ¨¡å‹ï¼‰
- `tenacity>=9.1.2` - é‡è©¦é‚è¼¯èˆ‡æŒ‡æ•¸å›é€€
- `pyyaml>=6.0` - YAML é…ç½®è§£æ
- `python-dotenv>=1.1.1` - ç’°å¢ƒè®Šæ•¸ç®¡ç†
- `transformers>=4.40.0` - Hugging Face åˆ†è©å™¨ï¼ˆå¯©è¨ˆåŠŸèƒ½å¿…è¦ï¼‰

### é–‹ç™¼ä¾è³´ï¼ˆå¯é¸ï¼‰

```bash
# å®‰è£æ¸¬è©¦ä¾è³´
pip install -e ".[test]"
```

## å¿«é€Ÿé–‹å§‹

### 1. è¨­å®šç’°å¢ƒè®Šæ•¸

**æ–¹æ³•ä¸€ï¼šä½¿ç”¨ .env æª”æ¡ˆï¼ˆæ¨è–¦ï¼‰**

```bash
# è¤‡è£½ç¯„ä¾‹æª”æ¡ˆ
cp .env.example .env

# ç·¨è¼¯ .env æª”æ¡ˆï¼Œå¡«å…¥ä½ çš„ API é‡‘é‘°
nano .env  # æˆ–ä½¿ç”¨å…¶ä»–ç·¨è¼¯å™¨
```

`.env` æª”æ¡ˆå…§å®¹ç¯„ä¾‹ï¼š
```env
OPENAI_API_KEY=sk-your-actual-api-key-here
# OPENAI_BASE_URL=https://api.example.com/v1  # å¯é¸
# LOG_LEVEL=INFO  # å¯é¸
```

**æ–¹æ³•äºŒï¼šç›´æ¥è¨­å®šç’°å¢ƒè®Šæ•¸**

```bash
# Linux/macOS
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_BASE_URL="https://api.example.com/v1"  # å¯é¸
export LOG_LEVEL=INFO  # å¯é¸

# Windows (PowerShell)
$env:OPENAI_API_KEY="your-api-key-here"
$env:OPENAI_BASE_URL="https://api.example.com/v1"  # å¯é¸
$env:LOG_LEVEL="INFO"  # å¯é¸
```

**ç’°å¢ƒè®Šæ•¸èªªæ˜ï¼š**

| è®Šæ•¸ | å¿…è¦æ€§ | èªªæ˜ |
|------|--------|------|
| `OPENAI_API_KEY` | å¿…è¦ | OpenAI API é‡‘é‘°ï¼Œç•¶é…ç½®æª”ä¸­ `api_key: null` æ™‚ä½¿ç”¨ |
| `OPENAI_BASE_URL` | å¯é¸ | è‡ªè¨‚ API ç«¯é»ï¼Œç”¨æ–¼ç¬¬ä¸‰æ–¹ç›¸å®¹ API |
| `ANTHROPIC_API_KEY` | å¯é¸ | Anthropic API é‡‘é‘°ï¼Œç”¨æ–¼ Claude æ¨¡å‹ |
| `ANTHROPIC_BASE_URL` | å¯é¸ | è‡ªè¨‚ Anthropic API ç«¯é» |
| `LOG_LEVEL` | å¯é¸ | æ—¥èªŒç­‰ç´š (DEBUG/INFO/WARNING/ERROR/CRITICAL) |
| `HF_ENDPOINT` | å¯é¸ | Hugging Face é¡åƒç«™ï¼Œç”¨æ–¼åŠ é€Ÿåˆ†è©å™¨ä¸‹è¼‰ |

> ğŸ’¡ **æç¤º**: æ›´å¤šç’°å¢ƒè®Šæ•¸èªªæ˜è«‹åƒè€ƒ [ç’°å¢ƒè®Šæ•¸æ–‡ä»¶](docs/environment-variables.md)

### 2. å»ºç«‹å¯©è¨ˆé…ç½®æª”

å»ºç«‹ YAML é…ç½®æª”ï¼ˆä¾‹å¦‚ `my_audit.yaml`ï¼‰ï¼š

```yaml
# API ç«¯é»é…ç½®
endpoint:
  url: "https://api.example.com/v1/chat/completions"
  model: "meta-llama/Llama-3.1-8B"
  api_key: null  # å¾ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY è®€å–

# åˆ†è©å™¨é…ç½®
tokenizer:
  model_name_or_path: "meta-llama/Llama-3.1-8B"

# è§£ç¢¼åƒæ•¸
decoding:
  temperature: 0.0
  top_p: 1.0
  max_tokens: 128
  seed: 1234

# æ¸¬è©¦å¥—ä»¶
suites:
  quick:
    - tokenizer_fingerprint
    - perturbation
    - arithmetic_json
    - style_bias

# æª¢æ¸¬é–¾å€¼
thresholds:
  fingerprint_avg_diff_pct: 2.0
  perturb_top1_change_pct: 20.0
  arithmetic_acc: 0.9
  json_valid_rate: 0.9
  style_fixed_prefix_rate: 0.2
  style_format_violation_rate: 0.1

# åŸ·è¡Œé…ç½®
run:
  parallel: 1
  rate_limit_sleep: 0.2
  retries: 2
  timeout_sec: 60
```

å®Œæ•´é…ç½®ç¯„ä¾‹è«‹åƒè€ƒ `configs/audit_example.yaml`ã€‚

### 3. åŸ·è¡Œå¯©è¨ˆ

```bash
# ä½¿ç”¨é…ç½®æª”åŸ·è¡Œå¯©è¨ˆ
llm-testkit audit --config my_audit.yaml

# æŒ‡å®šæ¸¬è©¦å¥—ä»¶
llm-testkit audit --config my_audit.yaml --suite quick

# æŒ‡å®šè¼¸å‡ºç›®éŒ„
llm-testkit audit --config my_audit.yaml --output output/my_results
```

### 4. æª¢è¦–å ±å‘Š

åŸ·è¡Œå®Œæˆå¾Œï¼Œæœƒåœ¨è¼¸å‡ºç›®éŒ„ç”¢ç”Ÿå…©ç¨®æ ¼å¼çš„å ±å‘Šï¼š

- `report.json` - æ©Ÿå™¨å¯è®€æ ¼å¼ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
- `report.md` - äººé¡å¯è®€æ ¼å¼ï¼Œä¾¿æ–¼å¿«é€Ÿæª¢è¦–

```bash
# æª¢è¦– Markdown å ±å‘Š
cat output/audit/report.md
```

## CLI ä½¿ç”¨æ–¹å¼

### ä¸»å‘½ä»¤

```bash
llm-testkit --help
```

### Audit å­å‘½ä»¤

```bash
llm-testkit audit --help
```

**åƒæ•¸èªªæ˜ï¼š**

- `--config` (å¿…è¦): å¯©è¨ˆé…ç½®æª”è·¯å¾‘ï¼ˆYAML æ ¼å¼ï¼‰
- `--suite` (å¯é¸): æ¸¬è©¦å¥—ä»¶åç¨±ï¼Œé è¨­ç‚º `quick`
- `--output` (å¯é¸): å ±å‘Šè¼¸å‡ºç›®éŒ„ï¼Œé è¨­ç‚º `output/audit`

## æ”¯æ´çš„æ¨¡å‹èˆ‡åˆ†è©å™¨

å¯©è¨ˆæ¨¡çµ„ä½¿ç”¨ Hugging Face `transformers` åº«ï¼Œæ”¯æ´æ‰€æœ‰ä¸»æµé–‹æºæ¨¡å‹ï¼š

### Meta Llama ç³»åˆ—
- `meta-llama/Llama-3.1-8B`
- `meta-llama/Llama-3.1-70B`
- `meta-llama/Llama-2-7b-hf`
- `meta-llama/Llama-2-13b-hf`

### Qwen ç³»åˆ—
- `Qwen/Qwen2.5-7B`
- `Qwen/Qwen2.5-14B`
- `Qwen/Qwen2.5-72B`
- `Qwen/Qwen1.5-7B`

### GLM ç³»åˆ—
- `THUDM/glm-4-9b`
- `THUDM/chatglm3-6b`

### Mistral ç³»åˆ—
- `mistralai/Mistral-7B-v0.1`
- `mistralai/Mixtral-8x7B-v0.1`

### å…¶ä»–é–‹æºæ¨¡å‹
- `google/gemma-7b`
- `microsoft/phi-2`
- `tiiuae/falcon-7b`
- `gpt2`ï¼ˆå…¬é–‹å¯ç”¨ï¼Œé©åˆæ¸¬è©¦ï¼‰

### ä½¿ç”¨æœ¬åœ°æ¨¡å‹

è‹¥æ¨¡å‹å·²ä¸‹è¼‰åˆ°æœ¬åœ°ï¼Œå¯ç›´æ¥æŒ‡å®šè·¯å¾‘ï¼š

```yaml
tokenizer:
  model_name_or_path: "/path/to/local/model"
```

### é å…ˆä¸‹è¼‰åˆ†è©å™¨

é¦–æ¬¡ä½¿ç”¨æ™‚ï¼Œåˆ†è©å™¨æœƒè‡ªå‹•å¾ Hugging Face Hub ä¸‹è¼‰ã€‚è‹¥éœ€é›¢ç·šä½¿ç”¨ï¼Œå¯é å…ˆä¸‹è¼‰ï¼š

```bash
# ä½¿ç”¨ Python é å…ˆä¸‹è¼‰
python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('meta-llama/Llama-3.1-8B')"

# æˆ–ä½¿ç”¨ Hugging Face CLI
pip install huggingface_hub
huggingface-cli download meta-llama/Llama-3.1-8B
```

## API å®¢æˆ¶ç«¯æ”¯æ´

LLM TestKit æä¾›å…©ç¨® API å®¢æˆ¶ç«¯å¯¦ä½œï¼Œå¯ç”¨æ–¼èˆ‡ä¸åŒçš„ LLM æœå‹™äº’å‹•ï¼š

### OpenAI ç›¸å®¹ API

æ”¯æ´ OpenAI å®˜æ–¹ API åŠæ‰€æœ‰ç›¸å®¹çš„ç¬¬ä¸‰æ–¹æœå‹™ï¼ˆå¦‚ Azure OpenAIã€æœ¬åœ°éƒ¨ç½²ç­‰ï¼‰ã€‚

```python
from llm_testkit.backend import OpenAICompatibleAPI

async with OpenAICompatibleAPI(
    model_name="gpt-4",
    api_key="your-api-key",
    base_url="https://api.openai.com/v1"  # å¯é¸
) as client:
    response = await client.generate(
        messages=[{"role": "user", "content": "Hello!"}],
        max_tokens=100,
        temperature=0.7
    )
    print(response.choices[0].message.content)
```

### Anthropic API

æ”¯æ´ Anthropic Claude æ¨¡å‹ç³»åˆ—ï¼ŒåŒ…å«é‡å°é•·æ™‚é–“æ¨ç†è«‹æ±‚çš„æœ€ä½³åŒ–ã€‚

```python
from llm_testkit.backend import AnthropicAPI

async with AnthropicAPI(
    model_name="claude-sonnet-4-20250514",
    api_key="your-anthropic-api-key",
    base_url="https://api.anthropic.com"  # å¯é¸
) as client:
    response = await client.generate(
        messages=[{"role": "user", "content": "Hello!"}],
        system="You are a helpful assistant.",  # å¯é¸
        max_tokens=2048,
        temperature=0.5
    )
    print(response.content[0].text)
```

**ç‰¹æ€§ï¼š**
- è‡ªå‹•é‡è©¦æ©Ÿåˆ¶ï¼ˆé€Ÿç‡é™åˆ¶ã€é€£ç·šéŒ¯èª¤ã€è¶…æ™‚ï¼‰
- æŒ‡æ•¸é€€é¿ç­–ç•¥ï¼ˆæœ€å¤š 3 æ¬¡é‡è©¦ï¼‰
- Socket keepalive æ”¯æ´é•·æ™‚é–“æ¨ç†è«‹æ±‚
- å®Œæ•´çš„éŒ¯èª¤è™•ç†èˆ‡é¡å‹æç¤º
- Async context manager è‡ªå‹•è³‡æºç®¡ç†

## ç¨‹å¼åŒ–ä½¿ç”¨

é™¤äº† CLIï¼Œä¹Ÿå¯ä»¥åœ¨ Python ç¨‹å¼ç¢¼ä¸­ç›´æ¥ä½¿ç”¨å¯©è¨ˆæ¨¡çµ„ï¼š

```python
import asyncio
from pathlib import Path
from llm_testkit.audit.config import AuditConfig
from llm_testkit.audit.runner import AuditRunner

async def run_audit():
    # è¼‰å…¥é…ç½®
    config = AuditConfig.from_yaml("my_audit.yaml")
    
    # å»ºç«‹åŸ·è¡Œå™¨
    runner = AuditRunner(config)
    
    try:
        # åŸ·è¡Œæ¸¬è©¦å¥—ä»¶
        results = await runner.run_suite("quick")
        
        # ç”¢ç”Ÿå ±å‘Š
        runner.generate_report(results, "output/my_audit")
        
        # æª¢æŸ¥çµæœ
        for result in results:
            print(f"{result.name}: {'é€šé' if result.passed else 'å¤±æ•—'}")
            print(f"  æŒ‡æ¨™: {result.metrics}")
            if result.notes:
                print(f"  å‚™è¨»: {result.notes}")
    
    finally:
        # é—œé–‰è³‡æº
        await runner.close()

# åŸ·è¡Œ
asyncio.run(run_audit())
```

## å°ˆæ¡ˆçµæ§‹

```
llm_testkit/
â”œâ”€â”€ src/llm_testkit/          # ä¸»è¦åŸå§‹ç¢¼
â”‚   â”œâ”€â”€ audit/                # å¯©è¨ˆæ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ detectors/        # æª¢æ¸¬å™¨å¯¦ä½œ
â”‚   â”‚   â”œâ”€â”€ cli.py            # CLI å…¥å£
â”‚   â”‚   â”œâ”€â”€ runner.py         # å¯©è¨ˆåŸ·è¡Œå™¨
â”‚   â”‚   â””â”€â”€ config.py         # é…ç½®æ¨¡å‹
â”‚   â”œâ”€â”€ backend/              # API å®¢æˆ¶ç«¯å¯¦ä½œ
â”‚   â”‚   â”œâ”€â”€ openai_api.py     # OpenAI ç›¸å®¹ API åŒ…è£å™¨
â”‚   â”‚   â””â”€â”€ anthropic_api.py  # Anthropic API åŒ…è£å™¨
â”‚   â”œâ”€â”€ core/                 # æ ¸å¿ƒå·¥å…·
â”‚   â”‚   â”œâ”€â”€ tokenizer.py      # åˆ†è©å™¨æŠ½è±¡
â”‚   â”‚   â””â”€â”€ metrics.py        # æŒ‡æ¨™è¨ˆç®—å·¥å…·
â”‚   â”œâ”€â”€ utils/                # å·¥å…·æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ config.py         # YAML é…ç½®è¼‰å…¥å™¨
â”‚   â”‚   â”œâ”€â”€ io.py             # JSON/JSONL æª”æ¡ˆæ“ä½œ
â”‚   â”‚   â””â”€â”€ logging.py        # æ—¥èªŒå·¥å…·
â”‚   â””â”€â”€ main.py               # çµ±ä¸€ CLI å…¥å£é»
â”œâ”€â”€ configs/                  # é…ç½®æª”æ¡ˆ
â”‚   â”œâ”€â”€ default.yaml          # é è¨­é…ç½®
â”‚   â””â”€â”€ audit_example.yaml    # å¯©è¨ˆé…ç½®ç¯„ä¾‹
â”œâ”€â”€ tests/                    # æ¸¬è©¦æª”æ¡ˆ
â”œâ”€â”€ output/                   # ç”¢ç”Ÿçš„è¼¸å‡ºï¼ˆgitignoredï¼‰
â”œâ”€â”€ pyproject.toml            # å°ˆæ¡ˆé…ç½®
â””â”€â”€ README.md                 # æœ¬æª”æ¡ˆ
```

## é–‹ç™¼æŒ‡å—

### ç¨‹å¼ç¢¼å“è³ªå·¥å…·

å°ˆæ¡ˆä½¿ç”¨ä»¥ä¸‹å·¥å…·ç¶­è­·ç¨‹å¼ç¢¼å“è³ªï¼š

- **Ruff**: Linter èˆ‡ Formatterï¼ˆå–ä»£ flake8ã€blackã€isortï¼‰
- **Pyright**: å‹åˆ¥æª¢æŸ¥å™¨
- **Pre-commit**: Git hooks è‡ªå‹•åŒ–

### å¸¸ç”¨å‘½ä»¤

```bash
# æ ¼å¼åŒ–ç¨‹å¼ç¢¼
ruff format .

# Lint èˆ‡è‡ªå‹•ä¿®æ­£
ruff check --fix .

# å‹åˆ¥æª¢æŸ¥
pyright src

# åŸ·è¡Œ pre-commit hooks
pre-commit run --all-files

# å»ºç½®å¥—ä»¶
python -m build
```

### é…ç½®æª”æ¡ˆ

- **Ruff**: `ruff.toml`
  - è¡Œé•·åº¦: 100 å­—å…ƒ
  - ç›®æ¨™: Python 3.12
  - å¼•è™Ÿé¢¨æ ¼: é›™å¼•è™Ÿ
  - Docstring æ…£ä¾‹: Google style

- **Pyright**: `pyrightconfig.json`
  - æ¨¡å¼: standard
  - Python ç‰ˆæœ¬: 3.12

- **Pre-commit**: `.pre-commit-config.yaml`
  - Ruff è‡ªå‹•ä¿®æ­£èˆ‡æ ¼å¼åŒ–

## å¸¸è¦‹å•é¡Œ

### Q: åˆ†è©å™¨ä¸‹è¼‰å¤±æ•—æ€éº¼è¾¦ï¼Ÿ

**A:** å¯èƒ½åŸå› èˆ‡è§£æ±ºæ–¹æ¡ˆï¼š

1. **ç¶²è·¯å•é¡Œ**: ä½¿ç”¨ä»£ç†æˆ–é¡åƒç«™
   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

2. **æ¬Šé™å•é¡Œ**: æŸäº›æ¨¡å‹éœ€è¦æˆæ¬Šï¼ˆå¦‚ Llamaï¼‰
   - å‰å¾€ Hugging Face ç”³è«‹å­˜å–æ¬Šé™
   - ä½¿ç”¨ `huggingface-cli login` ç™»å…¥

3. **é›¢ç·šç’°å¢ƒ**: é å…ˆä¸‹è¼‰æ¨¡å‹åˆ°æœ¬åœ°
   ```bash
   huggingface-cli download meta-llama/Llama-3.1-8B --local-dir ./models/llama31
   ```
   ç„¶å¾Œåœ¨é…ç½®ä¸­ä½¿ç”¨æœ¬åœ°è·¯å¾‘ï¼š
   ```yaml
   tokenizer:
     model_name_or_path: "./models/llama31"
   ```

### Q: API ä¸å›å‚³ usage è³‡è¨Šæ€éº¼è¾¦ï¼Ÿ

**A:** åˆ†è©å™¨æŒ‡ç´‹æª¢æ¸¬æœƒè‡ªå‹•è™•ç†æ­¤æƒ…æ³ï¼š
- è‹¥ API ä¸å›å‚³ `usage.prompt_tokens`ï¼Œæª¢æ¸¬å™¨æœƒæ¨™è¨˜ç‚ºå¤±æ•—
- å ±å‘Šä¸­æœƒè¨»æ˜ã€ŒAPI æœªå›å‚³ usage è³‡è¨Šã€
- å…¶ä»–æª¢æ¸¬å™¨ä¸å—å½±éŸ¿ï¼Œä»æœƒæ­£å¸¸åŸ·è¡Œ

### Q: å¦‚ä½•èª¿æ•´æª¢æ¸¬éˆæ•åº¦ï¼Ÿ

**A:** é€éä¿®æ”¹é…ç½®æª”ä¸­çš„ `thresholds` å€å¡Šï¼š

```yaml
thresholds:
  # æé«˜é–¾å€¼ = é™ä½éˆæ•åº¦ï¼ˆæ›´å¯¬é¬†ï¼‰
  fingerprint_avg_diff_pct: 5.0      # é è¨­ 2.0
  perturb_top1_change_pct: 30.0      # é è¨­ 20.0
  
  # é™ä½é–¾å€¼ = æé«˜éˆæ•åº¦ï¼ˆæ›´åš´æ ¼ï¼‰
  arithmetic_acc: 0.95               # é è¨­ 0.9
```

### Q: å¦‚ä½•è™•ç†é€Ÿç‡é™åˆ¶ï¼Ÿ

**A:** èª¿æ•´é…ç½®æª”ä¸­çš„ `run` å€å¡Šï¼š

```yaml
run:
  rate_limit_sleep: 1.0    # å¢åŠ è«‹æ±‚é–“å»¶é²ï¼ˆç§’ï¼‰
  retries: 5               # å¢åŠ é‡è©¦æ¬¡æ•¸
  timeout_sec: 120         # å¢åŠ è¶…æ™‚æ™‚é–“
```

## æˆæ¬Š

æœ¬å°ˆæ¡ˆéµå¾ªå°ˆæ¡ˆæˆæ¬Šæ¢æ¬¾ã€‚

## è²¢ç»

æ­¡è¿è²¢ç»æ–°çš„æª¢æ¸¬å™¨æˆ–æ”¹é€²ç¾æœ‰åŠŸèƒ½ï¼

---

æ›´å¤šè©³ç´°è³‡è¨Šè«‹åƒè€ƒ `src/llm_testkit/audit/README.md`ã€‚
